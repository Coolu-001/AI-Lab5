Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
 >>> Phase 1: Warming up Text Branch (Epoch 0)
Epoch 1/50:   4%|â–Š                     | 7/200 [00:55<25:33,  7.95s/it, loss=1.1497, lr=1.75e-07]
Traceback (most recent call last):
  File "/Users/caolu/Desktop/AI_Lab5/main.py", line 113, in <module>
    val_accuracy = trainer.train(train_dataloader, valid_dataloader, config.epochs, evaluate_every=1)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/Desktop/AI_Lab5/train_validate.py", line 122, in train
    loss.backward()
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
