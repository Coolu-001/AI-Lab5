Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/50: 100%|████████████████████| 200/200 [14:44<00:00,  4.42s/it, loss=1.0660, lr=5.00e-06]
Evaluating: 100%|████████████████████████████████████████████████| 50/50 [00:48<00:00,  1.03it/s]

[Modality Weights] Text: 0.5003, Image: 0.4996
Epoch 2/50: 100%|████████████████████| 200/200 [13:50<00:00,  4.15s/it, loss=1.0032, lr=1.00e-05]
Evaluating: 100%|████████████████████████████████████████████████| 50/50 [00:44<00:00,  1.11it/s]

[Modality Weights] Text: 0.5016, Image: 0.4994
Epoch 3/50: 100%|████████████████████| 200/200 [13:55<00:00,  4.18s/it, loss=0.9118, lr=1.50e-05]
Evaluating: 100%|████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]

[Modality Weights] Text: 0.5029, Image: 0.5003
Epoch 4/50: 100%|████████████████████| 200/200 [13:53<00:00,  4.17s/it, loss=0.7361, lr=2.00e-05]
Evaluating: 100%|████████████████████████████████████████████████| 50/50 [00:46<00:00,  1.08it/s]

[Modality Weights] Text: 0.5030, Image: 0.5021
Epoch 5/50: 100%|████████████████████| 200/200 [14:22<00:00,  4.31s/it, loss=0.7299, lr=2.50e-05]
Evaluating: 100%|████████████████████████████████████████████████| 50/50 [00:45<00:00,  1.10it/s]

[Modality Weights] Text: 0.5027, Image: 0.5040
EarlyStopping counter: 1 out of 7
Epoch 6/50:  38%|███████▉             | 76/200 [09:07<14:53,  7.20s/it, loss=0.6733, lr=2.69e-05]
Traceback (most recent call last):
  File "/Users/caolu/Desktop/AI_Lab5/main.py", line 136, in <module>
  File "/Users/caolu/Desktop/AI_Lab5/train_validate.py", line 108, in train
    train_pred_labels, loss = self.model(texts, texts_mask, images, labels)
                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/Desktop/AI_Lab5/MultiModelTranformer.py", line 224, in forward
    text_feat = self.text_model(texts, texts_mask) # [Batch, 768]
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/Desktop/AI_Lab5/MultiModelTranformer.py", line 45, in forward
    outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py", line 976, in forward
    encoder_outputs = self.encoder(
                      ^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py", line 631, in forward
    layer_outputs = layer_module(
                    ^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py", line 520, in forward
    self_attention_outputs = self.attention(
                             ^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py", line 447, in forward
    self_outputs = self.self(
                   ^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py", line 370, in forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
