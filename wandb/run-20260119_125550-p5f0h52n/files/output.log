preprocessor_config.json: 100%|██████████████████████| 316/316 [00:00<00:00, 484kB/s]
tokenizer_config.json: 100%|█████████████████████████| 592/592 [00:00<00:00, 426kB/s]
vocab.json: 862kB [00:00, 2.37MB/s]
merges.txt: 525kB [00:00, 4.93MB/s]
tokenizer.json: 2.22MB [00:00, 20.8MB/s]
special_tokens_map.json: 100%|███████████████████████| 389/389 [00:00<00:00, 956kB/s]
config.json: 4.19kB [00:00, 3.32MB/s]
Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
pytorch_model.bin: 100%|██████████████████████████| 605M/605M [00:44<00:00, 13.7MB/s]
Epoch 1/50:   0%|                                            | 0/200 [00:09<?, ?it/s]
Traceback (most recent call last):
  File "/Users/caolu/Desktop/AI_Lab5/main.py", line 130, in <module>
    val_accuracy = trainer.train(train_dataloader, valid_dataloader, config.epochs, evaluate_every=1)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/Desktop/AI_Lab5/train_validate.py", line 108, in train
    for batch in tqdm(train_dataloader, desc=f"Epoch {epoch+1}/{num_epochs}"):
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/tqdm/std.py", line 1181, in __iter__
    for obj in iterable:
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1465, in _next_data
    return self._process_data(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/dataloader.py", line 1491, in _process_data
    data.reraise()
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/_utils.py", line 715, in reraise
    raise exception
TypeError: Caught TypeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py", line 351, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "/Users/caolu/Desktop/AI_Lab5/load_dataset.py", line 56, in __getitem__
    image = self.transform(image)
            ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torchvision/transforms/transforms.py", line 137, in __call__
    return F.to_tensor(pic)
           ^^^^^^^^^^^^^^^^
  File "/Users/caolu/opt/anaconda3/envs/multi/lib/python3.11/site-packages/torchvision/transforms/functional.py", line 142, in to_tensor
    raise TypeError(f"pic should be PIL Image or ndarray. Got {type(pic)}")
TypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>
